---
title: Supervised Learning
output: 
  html_document:
    toc: true
    theme: united
---

# Introduction


Reference: https://lgatto.github.io/IntroMachineLearningWithR/supervised-learning.html

See topics:

- Introduction
- Preview
- Model performance
- Cross-validation
- Classification performance
  - Confusion matrix
- Random forest
  - Decision tree
- Data preprocessing
  - Missing values
  - RSME
  - Median imputation

## Test v. Training Data

A key concept we will start using in this section is splitting data into 2 separate tibbles. One will be used to training our data, and the other to test the resulting model. This helps us keep from over-training our data.

We will normally use the function `createDataPartition` from the `caret` library. 

```{r, eval=FALSE, echo=TRUE}
library(caret)
library(tidyverse)

full_tibble <- tibble(
  from = seq(1, 100),
  to = seq(100, 1)
)

# Get a vector of integers, referring to the rows that will be in our training data.
index_of_training_rows <- createDataPartition( 
    full_tibble$from,  # a vector from our data
    p = 0.3,           # percentage of data for the training set
    list = FALSE,      # don't return a list of the 0 or 1 values
    times = 1          # how many splits?
    )

# Make our two new tibbles. One for training, one or testing.

t_train = full_tibble[  index_of_training_rows, ] # Note the comma!
t_test  = full_tibble[ -index_of_training_rows, ] # Note the - and the comma!

```

