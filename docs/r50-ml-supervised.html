<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Supervised Learning</title>

<script src="site_libs/header-attrs-2.25/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/united.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">EDA Textbook</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="r00-index.html">R</a>
</li>
<li>
  <a href="sql00-index.html">SQL</a>
</li>
<li>
  <a href="dv00-index.html">Tableau/PowerBI</a>
</li>
<li>
  <a href="http://ecampus.wvu.edu">eCampus</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Supervised Learning</h1>

</div>

<div id="TOC">
<ul>
<li><a href="#more-information" id="toc-more-information">More
information</a></li>
<li><a href="#decision-trees" id="toc-decision-trees">Decision Trees</a>
<ul>
<li><a href="#class-example" id="toc-class-example">Class
Example</a></li>
<li><a href="#regression-example" id="toc-regression-example">Regression
Example</a></li>
</ul></li>
<li><a href="#neural-network---simple-class"
id="toc-neural-network---simple-class">Neural Network - simple class</a>
<ul>
<li><a href="#build-a-model" id="toc-build-a-model">Build a
model</a></li>
<li><a href="#measure-accuracy-on-training-data"
id="toc-measure-accuracy-on-training-data">Measure accuracy on training
data</a></li>
<li><a href="#evaluate-on-test-data"
id="toc-evaluate-on-test-data">Evaluate on test data</a></li>
</ul></li>
<li><a href="#neural-network---multiple-classes"
id="toc-neural-network---multiple-classes">Neural Network - multiple
classes</a>
<ul>
<li><a href="#build-a-model-1" id="toc-build-a-model-1">Build a
model</a></li>
<li><a href="#measure-accuracy-on-training-data-1"
id="toc-measure-accuracy-on-training-data-1">Measure accuracy on
training data</a></li>
<li><a href="#measure-accuracy-on-test-data"
id="toc-measure-accuracy-on-test-data">Measure accuracy on test
data</a></li>
</ul></li>
<li><a href="#neural-network---numeric-output"
id="toc-neural-network---numeric-output">Neural Network - numeric
output</a>
<ul>
<li><a href="#build-a-model-2" id="toc-build-a-model-2">Build a
model</a></li>
<li><a href="#measure-accuracy-on-training-data-2"
id="toc-measure-accuracy-on-training-data-2">Measure accuracy on
training data</a></li>
<li><a href="#evaluate-on-test-data-1"
id="toc-evaluate-on-test-data-1">Evaluate on test data</a></li>
</ul></li>
<li><a href="#scaling-data" id="toc-scaling-data">Scaling data</a></li>
</ul>
</div>

<div id="more-information" class="section level1">
<h1>More information</h1>
<p>Here is great tutorial for approaches in machine learning: <a
href="https://lgatto.github.io/IntroMachineLearningWithR/supervised-learning.html"
class="uri">https://lgatto.github.io/IntroMachineLearningWithR/supervised-learning.html</a></p>
<p>This covers these topics:</p>
<ul>
<li>Introduction</li>
<li>Preview</li>
<li>Model performance</li>
<li>Cross-validation</li>
<li>Classification performance
<ul>
<li>Confusion matrix</li>
</ul></li>
<li>Random forest
<ul>
<li>Decision tree</li>
</ul></li>
<li>Data preprocessing
<ul>
<li>Missing values</li>
<li>RSME</li>
<li>Median imputation</li>
</ul></li>
</ul>
</div>
<div id="decision-trees" class="section level1 tabset">
<h1 class="tabset">Decision Trees</h1>
<p>Decision trees are a method for predicting an outcome from a set of
variables. They are great for creating easily-understandable trees.</p>
<div id="class-example" class="section level2">
<h2>Class Example</h2>
<p>This creates a decision tree to predict a textual (class) output.</p>
<pre class="r"><code>library(tidyverse)
library(rpart)
library(rpart.plot)

# Load data into a tibble
t &lt;- tibble(
  temp = c(67, 68, 70, 70, 76, 80, 85, 84, 89, 90, 91, 95, 100),
  raining = c(&#39;n&#39;, &#39;n&#39;, &#39;n&#39;, &#39;n&#39;, &#39;n&#39;,&#39;n&#39;,&#39;n&#39;,&#39;n&#39;,&#39;n&#39;,&#39;n&#39;,&#39;y&#39;, &#39;n&#39;, &#39;n&#39;),
  camped = c(&#39;Camped&#39;, &#39;No&#39;, &#39;No&#39;, &#39;No&#39;, &#39;No&#39;, &#39;No&#39;, &#39;Camped&#39;, &#39;Camped&#39;, &#39;Camped&#39;, &#39;Camped&#39;, &#39;No&#39;, &#39;No&#39;, &#39;No&#39;)
)

# Create the model
# https://stat.ethz.ch/R-manual/R-devel/library/rpart/html/rpart.control.html
#   formula: set output to the Species, and choose input fields
#   data: set to our tibble
#   minsplit: the minimum number of observations that must exist in a node in order for a split to be attempted. 
#   minbucket: the minimum number of observations in any terminal
#   method: class, meaning we are predicting a discrete variable
#   
m &lt;- rpart(formula = camped ~ temp + raining,
           data = t,
           minsplit = 8,
           minbucket = 5,
           method = &quot;class&quot;)

# Show results of model
rpart.plot(m)</code></pre>
<p><img src="r50-ml-supervised_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<pre class="r"><code># Create the predicted value and add it to our tibble
predicted &lt;- predict(m, t, type = &#39;class&#39;)
t &lt;- mutate( t, 
             predicted = predicted,
             is_correct = predicted == camped)

# Percentage correct
print(mean(t$is_correct))</code></pre>
<pre><code>## [1] 0.6923077</code></pre>
<pre class="r"><code># Show a confusion matrix
# Predicted values are in upper case.
table(str_to_upper(t$predicted), t$camped)</code></pre>
<pre><code>##         
##          Camped No
##   CAMPED      4  3
##   NO          1  5</code></pre>
</div>
<div id="regression-example" class="section level2">
<h2>Regression Example</h2>
<p>This creates a decision tree to predict a numeric output with
regression.</p>
<pre class="r"><code>library(tidyverse)
library(rpart)
library(rpart.plot)

# Load data into a tibble
t &lt;- tibble(
  temp = c(67, 68, 70, 70, 76, 80, 85, 84, 89, 90, 91, 95, 100),
  raining = c(&#39;n&#39;, &#39;n&#39;, &#39;n&#39;, &#39;n&#39;, &#39;n&#39;,&#39;n&#39;,&#39;n&#39;,&#39;n&#39;,&#39;n&#39;,&#39;n&#39;,&#39;y&#39;, &#39;n&#39;, &#39;n&#39;),
  camped = c(&#39;Camped&#39;, &#39;No&#39;, &#39;No&#39;, &#39;No&#39;, &#39;No&#39;, &#39;No&#39;, &#39;Camped&#39;, &#39;Camped&#39;, &#39;Camped&#39;, &#39;Camped&#39;, &#39;No&#39;, &#39;No&#39;, &#39;No&#39;)
)

# Create the model
# https://stat.ethz.ch/R-manual/R-devel/library/rpart/html/rpart.control.html
#   formula: set output to the Species, and choose input fields
#   data: set to our tibble
#   minsplit: the minimum number of observations that must exist in a node in order for a split to be attempted. 
#   minbucket: the minimum number of observations in any terminal
#   method: class, meaning we are predicting a discrete variable
m &lt;- rpart(formula = temp ~ camped + raining,
           data = t,
           minsplit = 1,
           minbucket = 1,
           method = &#39;anova&#39;)

# Show results of model
rpart.plot(m)</code></pre>
<p><img src="r50-ml-supervised_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<pre class="r"><code># Create the predicted value and add it to our tibble
predicted &lt;- predict(m, t)
t &lt;- mutate( t, 
             predicted = predicted,
             residual = predicted - temp)

# Residual value
hist(t$residual)</code></pre>
<p><img src="r50-ml-supervised_files/figure-html/unnamed-chunk-2-2.png" width="672" /></p>
</div>
</div>
<div id="neural-network---simple-class" class="section level1 tabset">
<h1 class="tabset">Neural Network - simple class</h1>
<p>Good reference videos:</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=bfmFfD2RIcg">Neural Network
in 5 minutes</a></li>
<li><a href="https://www.youtube.com/watch?v=CqOfi41LfDw">Stat Quest:
Math in the ANN</a></li>
</ul>
<p>We will use the <a
href="https://www.rdocumentation.org/packages/neuralnet/">NeuralNet
library</a>.</p>
<div id="build-a-model" class="section level2">
<h2>Build a model</h2>
<p>Below is a simple model created from some sample fraud data. It
predicts a simple 0/1 outcome.</p>
<pre class="r"><code>library(neuralnet)
library(tidyverse)

t_train &lt;- tribble( 
  ~fraud, ~jail01, ~age01, ~grump01,
  1, 1, .5, .5,
  1, 1, 1, 0, 
  1, 1, 0, 1,
  1, 0, .75, .8,
  1, 0, .6, 1,
  1, 1, .5, .9,
  0, 0, 0, 1, 
  0, 0, 0, 0,
  0, 0, 1, 1, 
  0, 0, 1, .8,
  )

t_test &lt;- tribble( 
  ~fraud, ~jail01, ~age01, ~grump01,
  1, 1, 0, 0,
  1, 1, .5, .25, 
  0, 0, 0, 1, 
  0, 0, 0, 0,
  0, 0, .9, .9, 
  0, 0, 7, .5,
)


# Set the random number generator&#39;s starting value. This makes our outputs repeatable, so we 
# don&#39;t get different results each time we run our software.
set.seed(1)

# The neuralnet function creates our model.
# Arguments:
#   formula: dependent variable ~ indepedent variables + ...
#   data: our tibble
#   hidden: how many hidden nodes should we use? Use an integer
#   linear.output: generally T for regression or F for classification
n &lt;- neuralnet(fraud ~ jail01 + age01,
               data = t_train,
               hidden = 1,
               linear.output = FALSE)

# View output
# Input notes are on the left, intermediate in the center, and output on the right.
# Steps tells us how many times the algorithm iterated through before stopping
# Error is the sse, but other options are also available.
plot(n)</code></pre>
</div>
<div id="measure-accuracy-on-training-data" class="section level2">
<h2>Measure accuracy on training data</h2>
<pre class="r"><code># Continue the previous code block, ...


# Measure accuracy on training set
# This code makes a new tibble showing the results in a easy to grasp form.
#   prediction: this is the output of our model. Use net.result[[1]] to grab the first item returned.
#   prediction01: the prediction outputs a decimal number. Since this problem has a 0/1, round.
prediction = n$net.result[[1]]
prediction01 = round(prediction, digits = 0)

# Create a confusion table
# Prediction is on the left, and actual on the top.
#
#             0                1       &lt;===  Actual outcome
# 0    Negative was True    Negative was False
# 1    Positive was False   Positive was True
# ^
#  \  
#    prediction
# 
train_table &lt;- table(prediction01, t_train$fraud )
print(train_table)</code></pre>
<pre><code>##             
## prediction01 0 1
##            0 2 0
##            1 2 6</code></pre>
<pre class="r"><code># Use coordinates to access our truth table
# We start at the top-left corner with [1,1], with [line, column]
# 
#       0        1
# 0   [1, 1]   [1, 2]
# 1   [2, 1]   [2, 2]

# Accuracy: true / total
# What is the total number of cases properly classified?
train_accuracy &lt;- (train_table[1, 1] + train_table[2, 2]) /  sum(train_table)

# Recall: true positives / (true positives + false negative)
# How many of the target cases did we find?
train_recall &lt;- train_table[2, 2] / (train_table[1, 2] + train_table[2, 2])

# Precision: true positives / (false positive + true positive)
train_precision &lt;- train_table[2, 2] / (train_table[2, 1] + train_table[2, 2])

print(paste(&#39;Accuracy&#39;, train_accuracy))</code></pre>
<pre><code>## [1] &quot;Accuracy 0.8&quot;</code></pre>
<pre class="r"><code>print(paste(&#39;Recall&#39;, train_recall))</code></pre>
<pre><code>## [1] &quot;Recall 1&quot;</code></pre>
<pre class="r"><code>print(paste(&#39;Precision&#39;, train_precision))</code></pre>
<pre><code>## [1] &quot;Precision 0.75&quot;</code></pre>
</div>
<div id="evaluate-on-test-data" class="section level2">
<h2>Evaluate on test data</h2>
<pre class="r"><code># Continue the previous code block, ...

# Now try test data.
#   n is our model
#   t_test is our data
p &lt;- predict(n, t_test)

# Evaluate the success by looking at the returned vector
# Note that we get a matrix back. We just want a vector, so access
# by using [ , 1] &lt;--- return all rows, but only first column.
prediction = p[,1]
prediction01 = round(prediction, digits = 0)

confusion &lt;- table(prediction01, t_test$fraud)

print(confusion)</code></pre>
<pre><code>##             
## prediction01 0 1
##            0 2 0
##            1 2 2</code></pre>
</div>
</div>
<div id="neural-network---multiple-classes"
class="section level1 tabset">
<h1 class="tabset">Neural Network - multiple classes</h1>
<div id="build-a-model-1" class="section level2">
<h2>Build a model</h2>
<p>We can use textual data. It will be encoded with each value set to a
0 or 1 field.</p>
<pre class="r"><code>library(neuralnet)
library(tidyverse)

# Load our iris dataset
data(iris)

set.seed(1)

# Create a sample vector of 1 and 0s, with 70% 1st and 30% 0. 
index &lt;- sample( c(1, 0), 
                 nrow(iris), 
                 replace = TRUE, 
                 prob = c(.7, .3) )

# Split data into test/train
t_train &lt;- filter( iris, index == 1 ) 
t_test &lt;- filter( iris, index == 0)

# Train algorithm
# Note that we are using a textual output, so instead of a single output node
# we now have one per label.
#   linear.output: generally T for regression or F for classification
n &lt;- neuralnet(Species  ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width,
               data = t_train,
               hidden = 2,
               linear.output = FALSE)

plot(n)</code></pre>
</div>
<div id="measure-accuracy-on-training-data-1" class="section level2">
<h2>Measure accuracy on training data</h2>
<p>Below is some sample code to measure the accuracy of the training /
test data.</p>
<pre class="r"><code># continue previous...

# Grab the matrix of results and round to the 0
matrix = round(n$net.result[[1]], digits = 0)

# Add column names
colnames(matrix) &lt;- list(&#39;setosa_node&#39;, &#39;versicolor_node&#39;, &#39;virginica_node&#39;)

# Convert matrix to a tibble
#     Add a column called predicted that says if we are 
#     predicting setota, versicolor, or virginica.
t_results &lt;- as.tibble(matrix)  %&gt;%
  mutate(predicted = ifelse(setosa_node == 1, &#39;setosa&#39;, 
                            ifelse(versicolor_node == 1, &#39;versicolor&#39;, &#39;virginica&#39;))) 


# Test accuracy with original data
accuracy = mean(t_results$predicted == t_train$Species)
print(accuracy)</code></pre>
<pre><code>## [1] 0.990566</code></pre>
<pre class="r"><code># See confusion table
table(str_to_upper(t_results$predicted), t_train$Species)</code></pre>
<pre><code>##             
##              setosa versicolor virginica
##   SETOSA         34          0         0
##   VERSICOLOR      0         34         1
##   VIRGINICA       0          0        37</code></pre>
</div>
<div id="measure-accuracy-on-test-data" class="section level2">
<h2>Measure accuracy on test data</h2>
<p>Below is some sample code to measure the accuracy of the training /
test data.</p>
<pre class="r"><code># continue previous...

predictions &lt;- predict(n, t_test)

# Grab the matrix of results and round to the 0
matrix = round(predictions, digits = 0)

# Add column names
colnames(matrix) &lt;- list(&#39;setosa_node&#39;, &#39;versicolor_node&#39;, &#39;virginica_node&#39;)

# Convert to tibble
t_results &lt;- as.tibble(matrix)  %&gt;%
  mutate(predicted = ifelse(setosa_node == 1, &#39;setosa&#39;, 
                            ifelse(versicolor_node == 1, &#39;versicolor&#39;, &#39;virginica&#39;))) 


# Test accuracy with original data
accuracy = mean(t_results$predicted == t_test$Species)
print(accuracy)</code></pre>
<pre><code>## [1] 0.9318182</code></pre>
<pre class="r"><code># See confusion table
table(t_results$predicted, t_test$Species)</code></pre>
<pre><code>##             
##              setosa versicolor virginica
##   setosa         16          1         0
##   versicolor      0         15         2
##   virginica       0          0        10</code></pre>
</div>
</div>
<div id="neural-network---numeric-output" class="section level1 tabset">
<h1 class="tabset">Neural Network - numeric output</h1>
<div id="build-a-model-2" class="section level2">
<h2>Build a model</h2>
<p>Below is a simple model predicting a numerical outcome. We use the
mtcars dataset.</p>
<pre class="r"><code>library(neuralnet)
library(tidyverse)

t &lt;- tribble( 
  ~height, ~weight, ~is_sumo,
  100, 100, 1, 
  200, 190, 0,
  150, 130, 1, 
  80, 200, 0, 
  175, 200, 1, 
  100, 80, 1,
  90, 70, 1,
  210, 200, 1,
  150, 160, 0,
  110, 140, 0,
  175, 200, 1, 
  103, 80, 1
)

# Scale the data and add a 0/1 
is_test = sample(x = c(0, 1),
                 size = 12,
                 replace = TRUE,
                 prob = c(0.5, 0.5))

# Setup the data to be scaled and have a 1/0 test/train variable
t &lt;- t %&gt;% 
  mutate(is_test = is_test, 
         height = scale(height),
         weight = scale(weight))


# Setup train/test tibbles
t_train &lt;- filter(t, is_test == 0)
t_test &lt;- filter(t, is_test == 1)


# Set the random number generator&#39;s starting value. This makes our outputs repeatable, so we 
# don&#39;t get different results each time we run our software.
set.seed(1)

# The neuralnet function creates our model.
# Arguments:
#   formula: dependent variable ~ indepedent variables + ...
#   data: our tibble
#   hidden: how many hidden nodes should we use? Use an integer
#   linear.output: generally T for regression or F for classification
n &lt;- neuralnet(formula = height ~ weight + is_sumo,
               data = t_train,
               hidden = 1,
               linear.output = TRUE)

# View output
# Input notes are on the left, intermediate in the center, and output on the right.
# Steps tells us how many times the algorithm iterated through before stopping
# Error is the sse, but other options are also available.
plot(n)</code></pre>
</div>
<div id="measure-accuracy-on-training-data-2" class="section level2">
<h2>Measure accuracy on training data</h2>
<pre class="r"><code># Continue the previous code block, ...


# Measure accuracy on training set
# This code makes a new tibble showing the results in a easy to grasp form.
#   prediction: this is the output of our model. Use net.result[[1]] to grab the first item returned.
prediction = n$net.result[[1]]

# Show error in a nice format
t_train &lt;- t_train %&gt;% 
  mutate(prediction = prediction,
         residual = prediction - weight)

# Show predicted v. actual
print(t_train)</code></pre>
<pre><code>## # A tibble: 7 × 6
##   height[,1] weight[,1] is_sumo is_test prediction[,1] residual[,1]
##        &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;          &lt;dbl&gt;        &lt;dbl&gt;
## 1     -0.814     -0.868       1       0         -0.722        0.146
## 2      1.39       0.836       0       0          1.41         0.570
## 3      0.289     -0.300       1       0          0.258        0.558
## 4     -0.814     -1.25        1       0         -0.836        0.410
## 5      1.61       1.03        1       0          1.61         0.580
## 6     -0.594     -0.110       0       0         -0.561       -0.451
## 7     -0.748     -1.25        1       0         -0.836        0.410</code></pre>
<pre class="r"><code># Find the sse
print((sum(t_train$residual ^ 2)))</code></pre>
<pre><code>## [1] 1.533005</code></pre>
</div>
<div id="evaluate-on-test-data-1" class="section level2">
<h2>Evaluate on test data</h2>
<pre class="r"><code># Continue the previous code block, ...

# Now try test data.
#   n is our model
#   t_test is our data
p &lt;- predict(n, t_test)

# Evaluate the success by looking at the returned vector
# Note that we get a matrix back. We just want a vector, so access
# by using [ , 1] &lt;--- return all rows, but only first column.
prediction = p[,1]

# Show error in a nice format
t_test &lt;- t_test %&gt;% 
  mutate(prediction = prediction,
         residual = prediction - weight)

# Show predicted v. actual
print(t_test)</code></pre>
<pre><code>## # A tibble: 5 × 6
##   height[,1] weight[,1] is_sumo is_test prediction residual[,1]
##        &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;
## 1     -1.26       1.03        0       1      1.52        0.496 
## 2      0.840      1.03        1       1      1.61        0.580 
## 3     -1.03      -1.44        1       1     -0.851       0.585 
## 4      0.289      0.268       0       1      0.235      -0.0332
## 5      0.840      1.03        1       1      1.61        0.580</code></pre>
<pre class="r"><code># Find the the sse
print((sum(t_test$residual ^ 2)))</code></pre>
<pre><code>## [1] 1.261366</code></pre>
</div>
</div>
<div id="scaling-data" class="section level1">
<h1>Scaling data</h1>
<p>Scale is a useful function for rescaling a set of input data.</p>
<pre class="r"><code># Rescale data
#   x: vector of data input
#   center: boolean, do we subtract column mean from each value (so mean = 0)?
#   scale: boolean, do we divide data by the sd after centering?
x2 &lt;- scale(x = c(1, 2, 3, 4, 4, 5,3),
      center = TRUE,
      scale = TRUE)

summary(x2)</code></pre>
<pre><code>##        V1         
##  Min.   :-1.5930  
##  1st Qu.:-0.4779  
##  Median :-0.1062  
##  Mean   : 0.0000  
##  3rd Qu.: 0.6372  
##  Max.   : 1.3806</code></pre>
<pre class="r"><code># We can also use the short form of this, relying on the defaults to get the 
# same result as above.
summary(scale(c(1, 2, 3, 4, 4, 5,3)))</code></pre>
<pre><code>##        V1         
##  Min.   :-1.5930  
##  1st Qu.:-0.4779  
##  Median :-0.1062  
##  Mean   : 0.0000  
##  3rd Qu.: 0.6372  
##  Max.   : 1.3806</code></pre>
<pre class="r"><code># We will often need to rescale the output to get it back into the normal form.
#   attributes:
#     dim
#     scaled:center
#     scaled:scale
attributes(x2)</code></pre>
<pre><code>## $dim
## [1] 7 1
## 
## $`scaled:center`
## [1] 3.142857
## 
## $`scaled:scale`
## [1] 1.345185</code></pre>
<pre class="r"><code># Get only the new data
scaled_data &lt;- x2[,1]
print(scaled_data)</code></pre>
<pre><code>## [1] -1.5929827 -0.8495908 -0.1061988  0.6371931  0.6371931  1.3805850 -0.1061988</code></pre>
<pre class="r"><code># Rescale by multiplying by the scale and adding the center.
scaled_data * attr(x2, &#39;scaled:scale&#39;) + attr(x2, &#39;scaled:center&#39;)</code></pre>
<pre><code>## [1] 1 2 3 4 4 5 3</code></pre>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
